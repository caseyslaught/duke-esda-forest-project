{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download GEDI imagery\n",
    "#### GEDI04_A - Level 4A Footprint Above Ground Biomass\n",
    "#### [ORNL DAAC](https://daac.ornl.gov/cgi-bin/dsviewer.pl?ds_id=2056)\n",
    "#### [ORNL GEDI Tutorial](https://github.com/ornldaac/gedi_tutorials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = [29.269398, -1.554519, 29.482104, -1.375895]\n",
    "start_date = dt.datetime(2021, 9, 1) \n",
    "end_date = dt.datetime(2022, 6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C2237824918-ORNL_CLOUD\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import requests\n",
    "from shapely.geometry import MultiPolygon, Polygon, box\n",
    "\n",
    "\n",
    "# DOI: Digital Object Identifiers\n",
    "doi = '10.3334/ORNLDAAC/2056' # GEDI L4A DOI \n",
    "\n",
    "# CMS: Common Metadata Repository\n",
    "cmr_url = 'https://cmr.earthdata.nasa.gov/search' \n",
    "search_url = f'{cmr_url}/collections.json?doi={doi}'\n",
    "\n",
    "res = requests.get(search_url)\n",
    "\n",
    "# Unique NASA-given concept ID for the GEDI 4A dataset, used to retrieve relevant files (or granules) for GEDI L4A\n",
    "concept_id = requests.get(search_url).json()['feed']['entry'][0]['id']\n",
    "print(concept_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMR formatted start and end times\n",
    "date_format = '%Y-%m-%dT%H:%M:%SZ'\n",
    "date_string = start_date.strftime(date_format) + ',' + end_date.strftime(date_format)\n",
    "\n",
    "bbox_string = ','.join(map(str, bbox))\n",
    "\n",
    "granules_list = []\n",
    "page_size, page_num = 2000, 1\n",
    "\n",
    "while True:    \n",
    "    cmr_params = {\n",
    "        \"collection_concept_id\": concept_id, \n",
    "        \"page_size\": page_size,\n",
    "        \"page_num\": page_num,\n",
    "        \"temporal\": date_string,\n",
    "        \"bounding_box[]\": bbox_string\n",
    "    }\n",
    "    \n",
    "    granules_url = f'{cmr_url}/granules.json'\n",
    "\n",
    "    granules_res = requests.get(granules_url, params=cmr_params)\n",
    "    granules = granules_res.json()['feed']['entry']\n",
    "        \n",
    "    if granules:\n",
    "        for g in granules:\n",
    "\n",
    "            granule_url = ''\n",
    "            granule_polygon = ''            \n",
    "            granule_size = float(g['granule_size'])\n",
    "            \n",
    "            if 'polygons' in g:\n",
    "                polygons= g['polygons']\n",
    "                multipolygons = []\n",
    "                for poly in polygons:\n",
    "                    i = iter(poly[0].split(\" \"))\n",
    "                    latlng = list(map(\" \".join, zip(i, i)))\n",
    "                    multipolygons.append(Polygon([[float(p.split(\" \")[1]), float(p.split(\" \")[0])] for p in latlng]))\n",
    "                    \n",
    "                granule_polygon = MultiPolygon(multipolygons)\n",
    "            \n",
    "            for links in g['links']:\n",
    "                if 'title' in links and links['title'].startswith('Download') \\\n",
    "                and links['title'].endswith('.h5'):\n",
    "                    granule_url = links['href']\n",
    "                    \n",
    "            granules_list.append([granule_url, granule_size, granule_polygon])\n",
    "               \n",
    "        page_num += 1\n",
    "        \n",
    "    else: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total granules found: 8\n",
      "Total file size (MB): 1399.12\n"
     ]
    }
   ],
   "source": [
    "granules_list.append(['bound', 0, box(bbox[0], bbox[1], bbox[2], bbox[3])]) # for plotting\n",
    "gedi_df = pd.DataFrame(granules_list, columns=[\"granule_url\", \"granule_size\", \"granule_polygon\"])\n",
    "gedi_df = gedi_df[gedi_df['granule_polygon'] != '']\n",
    "\n",
    "print(\"Total granules found:\", len(gedi_df.index)-1)\n",
    "print(\"Total file size (MB): %0.2f\" % gedi_df['granule_size'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(gedi_df, geometry=gedi_df.granule_polygon)\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "base = world.plot(color='white', edgecolor='black', figsize=(10, 10))\n",
    "\n",
    "# last row contains the bounding box (Red)\n",
    "ax = gdf[-1:].plot(ax=base, color='white', edgecolor='red', alpha=1.0)\n",
    "\n",
    "# all but the last row contains granule bounding geometry (Green)\n",
    "ax= gdf[:-1].plot(ax=base, color='green', edgecolor='green', alpha=0.4)\n",
    "\n",
    "minx, miny, maxx, maxy = gdf[-1:].geometry.total_bounds\n",
    "ax.set_xlim(minx-1, maxx+1)\n",
    "ax.set_ylim(miny-1, maxy+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "gedi_granules = gedi_df[:-1].drop_duplicates(subset=['granule_url'])\n",
    "gedi_granules.to_csv('data/gedi/granules.txt', columns = ['granule_url'], index=False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup EarthData Authorization\n",
    "#### 1. Go to https://urs.earthdata.nasa.gov/ and approve all the ORNL applications (not sure which one matters)\n",
    "#### 2. Setup credentials on container\n",
    "- #### cd ~; touch .netrc\n",
    "- #### echo \"machine urs.earthdata.nasa.gov login uid_goes_here password password_goes_here\" > .netrc\n",
    "- #### chmod 0600 .netrc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "wget -P data/gedi/ -nv -q --load-cookies ~/.urs_cookies --save-cookies ~/.urs_cookies --auth-no-challenge=on --keep-session-cookies --content-disposition -nc -i data/gedi/granules.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# removes query string from downloaded H5 files\n",
    "h5_files = glob.glob('./data/gedi/*.h5[?]*')\n",
    "for file in h5_files:\n",
    "    os.rename(file, file.split('.h5')[0] + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download HLS Sentinel-2 imagery\n",
    "### TODO: complete me!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
